"""
Download datasets for the AI platform
We'll use publicly available datasets from Kaggle/Hugging Face
"""

import os
import pandas as pd
import requests
from datasets import load_dataset
import json

def download_sales_data():
    """
    Download retail sales dataset for time series forecasting
    Using: Store Item Demand Forecasting Challenge from Kaggle
    """
    print("üìä Downloading sales dataset...")
    
    # We'll use Hugging Face datasets - easier access
    # This is a sample retail sales dataset
    url = "https://raw.githubusercontent.com/datasets/gdp/main/data/gdp.csv"
    
    # For now, let's create synthetic sales data (realistic approach)
    # In production, you'd use real company data
    
    import numpy as np
    from datetime import datetime, timedelta
    
    # Generate 3 years of daily sales data for 10 products
    start_date = datetime(2021, 1, 1)
    dates = [start_date + timedelta(days=x) for x in range(1095)]  # 3 years
    
    data = []
    for product_id in range(1, 11):
        base_sales = np.random.randint(50, 200)
        trend = np.linspace(0, 50, len(dates))
        seasonality = 30 * np.sin(np.linspace(0, 6*np.pi, len(dates)))
        noise = np.random.normal(0, 10, len(dates))
        
        for i, date in enumerate(dates):
            sales = base_sales + trend[i] + seasonality[i] + noise[i]
            sales = max(0, int(sales))  # No negative sales
            
            data.append({
                'date': date.strftime('%Y-%m-%d'),
                'product_id': f'PROD_{product_id:03d}',
                'sales_quantity': sales,
                'price': round(np.random.uniform(10, 100), 2),
                'revenue': round(sales * np.random.uniform(10, 100), 2)
            })
    
    df = pd.DataFrame(data)
    
    # Save to data/raw
    output_path = 'data/raw/sales_data.csv'
    df.to_csv(output_path, index=False)
    print(f"‚úÖ Saved sales data: {output_path}")
    print(f"   Shape: {df.shape}")
    print(f"   Date range: {df['date'].min()} to {df['date'].max()}")
    return df


def download_reviews_data():
    """
    Download customer reviews for sentiment analysis
    Using: Amazon reviews or similar from Hugging Face
    """
    print("\nüí¨ Downloading customer reviews dataset...")
    
    try:
        # Load a subset of Amazon reviews from Hugging Face
        dataset = load_dataset("amazon_polarity", split="train[:5000]")
        
        # Convert to pandas
        df = pd.DataFrame(dataset)
        df = df.rename(columns={'content': 'review_text', 'label': 'sentiment'})
        
        # Add metadata
        df['review_id'] = [f'REV_{i:05d}' for i in range(len(df))]
        df['product_id'] = [f'PROD_{np.random.randint(1, 11):03d}' for _ in range(len(df))]
        df['date'] = pd.date_range(start='2021-01-01', periods=len(df), freq='H')
        
        # Reorder columns
        df = df[['review_id', 'product_id', 'date', 'review_text', 'sentiment']]
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not download from Hugging Face: {e}")
        print("Creating synthetic review data instead...")
        
        # Synthetic review data
        positive_reviews = [
            "Great product! Exceeded my expectations.",
            "Love it! Will buy again.",
            "Excellent quality and fast shipping.",
            "Best purchase I've made this year.",
            "Highly recommended! Five stars."
        ]
        
        negative_reviews = [
            "Terrible quality. Very disappointed.",
            "Did not work as advertised. Waste of money.",
            "Poor customer service and defective product.",
            "Would not recommend. Returned it.",
            "Cheap materials and broke quickly."
        ]
        
        data = []
        for i in range(5000):
            if i % 2 == 0:  # 50% positive
                review = np.random.choice(positive_reviews)
                sentiment = 1
            else:  # 50% negative
                review = np.random.choice(negative_reviews)
                sentiment = 0
            
            data.append({
                'review_id': f'REV_{i:05d}',
                'product_id': f'PROD_{np.random.randint(1, 11):03d}',
                'date': pd.Timestamp('2021-01-01') + pd.Timedelta(hours=i),
                'review_text': review,
                'sentiment': sentiment
            })
        
        df = pd.DataFrame(data)
    
    # Save
    output_path = 'data/raw/reviews_data.csv'
    df.to_csv(output_path, index=False)
    print(f"‚úÖ Saved reviews data: {output_path}")
    print(f"   Shape: {df.shape}")
    print(f"   Sentiment distribution:")
    print(df['sentiment'].value_counts())
    return df


def create_business_documents():
    """
    Create sample business documents for RAG system
    In production, these would be real company docs, reports, policies, etc.
    """
    print("\nüìÑ Creating business documents for RAG...")
    
    documents = [
        {
            "filename": "company_overview.txt",
            "content": """
Company Overview - TechRetail Inc.

TechRetail Inc. is a leading e-commerce platform specializing in consumer electronics 
and smart home devices. Founded in 2020, we operate across 15 countries with over 
5 million active customers.

Our Mission: To make technology accessible and affordable for everyone.

Key Products:
- Smartphones and tablets
- Smart home devices
- Audio equipment
- Computer accessories
- Gaming peripherals

Annual Revenue: $500M (2023)
Employee Count: 1,200
Headquarters: San Francisco, CA
            """
        },
        {
            "filename": "q4_2023_report.txt",
            "content": """
Q4 2023 Financial Report

Executive Summary:
Q4 2023 showed strong growth with 25% YoY revenue increase. Smart home category 
led the growth with 40% increase driven by holiday season demand.

Key Metrics:
- Total Revenue: $150M (+25% YoY)
- Gross Margin: 35%
- Operating Income: $25M
- Customer Acquisition Cost: $45
- Average Order Value: $180

Top Performing Products:
1. SmartHome Hub Pro - 50,000 units sold
2. Wireless Earbuds X1 - 75,000 units sold
3. 4K Webcam - 30,000 units sold

Challenges:
- Supply chain disruptions in December
- Increased competition in audio category
- Rising customer acquisition costs
            """
        },
        {
            "filename": "marketing_strategy_2024.txt",
            "content": """
Marketing Strategy 2024

Objectives:
1. Increase brand awareness by 40%
2. Reduce customer acquisition cost by 20%
3. Launch 3 new product categories

Key Initiatives:

Social Media:
- Focus on TikTok and Instagram for Gen Z audience
- Influencer partnerships (budget: $2M)
- User-generated content campaigns

Content Marketing:
- Launch YouTube tech review channel
- Weekly blog posts on smart home trends
- Email newsletter with 500K subscribers

Paid Advertising:
- Google Ads: $5M annual budget
- Facebook/Instagram: $3M annual budget
- Retargeting campaigns for cart abandoners

Target Audience:
- Primary: Tech-savvy millennials (25-40)
- Secondary: Early adopters (18-25)
- Tertiary: Smart home enthusiasts (40-60)
            """
        },
        {
            "filename": "product_return_policy.txt",
            "content": """
Product Return & Refund Policy

Return Window: 30 days from delivery date

Eligible Items:
- Unopened products in original packaging
- Defective items (no time limit)
- Wrong items shipped

Non-Eligible Items:
- Digital downloads
- Personalized products
- Items marked as "Final Sale"

Return Process:
1. Initiate return request online
2. Print prepaid shipping label
3. Pack item securely
4. Drop off at any shipping location
5. Refund processed within 5-7 business days

Refund Method:
- Original payment method
- Store credit available for faster processing

Restocking Fee: 15% for opened electronics
Shipping Cost: Free returns for defective items, $8.99 for standard returns

Contact: returns@techretail.com or 1-800-TECH-RET
            """
        },
        {
            "filename": "employee_handbook.txt",
            "content": """
Employee Handbook - TechRetail Inc.

Work Hours:
- Standard: Monday-Friday, 9 AM - 5 PM
- Flexible hours available for engineering team
- Remote work: 2 days per week allowed

Benefits:
- Health insurance (medical, dental, vision)
- 401(k) with 5% company match
- 20 days PTO + 10 holidays
- $2,000 annual learning budget
- Stock options after 1 year

Performance Reviews:
- Conducted bi-annually (June and December)
- Based on OKRs (Objectives and Key Results)
- Salary adjustments considered after each review

Professional Development:
- Conference attendance budget
- Online course subscriptions (Coursera, Udemy)
- Internal mentorship program
- Lunch & learn sessions every Friday

Code of Conduct:
- Respect and inclusion for all
- No harassment or discrimination
- Confidentiality of customer data
- Ethical business practices
            """
        }
    ]
    
    # Save each document
    os.makedirs('data/documents', exist_ok=True)
    
    for doc in documents:
        filepath = f"data/documents/{doc['filename']}"
        with open(filepath, 'w') as f:
            f.write(doc['content'].strip())
        print(f"‚úÖ Created: {filepath}")
    
    # Also save as JSON for easier processing
    with open('data/documents/documents.json', 'w') as f:
        json.dump(documents, f, indent=2)
    
    print(f"\n‚úÖ Created {len(documents)} business documents")


def main():
    print("="*60)
    print("üì• DOWNLOADING DATASETS FOR AI PLATFORM")
    print("="*60)
    
    # Create directories if they don't exist
    os.makedirs('data/raw', exist_ok=True)
    os.makedirs('data/processed', exist_ok=True)
    os.makedirs('data/documents', exist_ok=True)
    
    # Download all datasets
    sales_df = download_sales_data()
    reviews_df = download_reviews_data()
    create_business_documents()
    
    print("\n" + "="*60)
    print("‚úÖ ALL DATASETS DOWNLOADED SUCCESSFULLY!")
    print("="*60)
    print("\nDataset Summary:")
    print(f"1. Sales Data: {len(sales_df)} records")
    print(f"2. Reviews Data: {len(reviews_df)} records")
    print(f"3. Business Documents: 5 files")
    print("\nNext Step: Data exploration and model training!")


if __name__ == "__main__":
    import numpy as np  # Import here for the script
    main()